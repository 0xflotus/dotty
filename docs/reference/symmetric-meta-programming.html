<h1><a href="#symmetric-meta-programming" id="symmetric-meta-programming">Symmetric Meta Programming</a></h1>
<p>Symmetric meta programming is a new framework for staging and for some
forms of macros. It is expressed as strongly and statically typed
code using two fundamental operations: quotations and splicing. A
novel aspect of the approach is that these two operations are
regulated by a phase consistency principle that treats quotes and
splices in exactly the same way.</p>
<h2><a href="#overview" id="overview">Overview</a></h2>
<h3><a href="#quotes-and-splices" id="quotes-and-splices">Quotes and Splices</a></h3>
<p>Symmetric meta programming is built on two well-known fundamental
operations: quotation and splicing.  Quotation is expressed as
<code>'(...)</code> or <code>'{...}</code> for expressions (both forms are equivalent) and
as <code>'[...]</code> for types. Splicing is expressed as a prefix <code>~</code> operator.</p>
<p>For example, the code below presents an inline function <code>assert</code>
which calls at compile-time a method <code>assertImpl</code> with a boolean
expression tree as argument. <code>assertImpl</code> evaluates the expression and
prints it again in an error message if it evaluates to <code>false</code>.</p>
<pre><code>import scala.quoted._

inline def assert(expr: =&gt; Boolean): Unit =
  ~ assertImpl(’(expr))

def assertImpl(expr: Expr[Boolean]) =
  ’{ if !(~expr) then throw new AssertionError(s&quot;failed assertion: ${~expr}&quot;) }
</code></pre>
<p>If <code>e</code> is an expression, then <code>’(e)</code> or <code>’{e}</code> represent the typed
abstract syntax tree representing <code>e</code>. If <code>T</code> is a type, then <code>’[T]</code>
represents the type structure representing <code>T</code>.  The precise
definitions of &quot;typed abstract syntax tree&quot; or &quot;type-structure&quot; do not
matter for now, the terms are used only to give some
intuition. Conversely, <code>~ e</code> evaluates the expression <code>e</code>, which must
yield a typed abstract syntax tree or type structure, and embeds the
result as an expression (respectively, type) in the enclosing program.</p>
<p>Quotations can have spliced parts in them; in this case the embedded
splices are evaluated and embedded as part of the formation of the
quotation.</p>
<p>Quotes and splices are duals of each other. For arbitrary
expressions <code>e</code> and types <code>T</code> we have:</p>
<pre><code>~’(e) = e
’(~e) = e
~’[T] = T
’[~T] = T
</code></pre>
<h3><a href="#types-for-quotations" id="types-for-quotations">Types for Quotations</a></h3>
<p>The type signatures of quotes and splices can be described using
two fundamental types:</p>
<ul>
<li><code>Expr[T]</code>: abstract syntax trees representing expressions of type <code>T</code></li>
<li><code>Type[T]</code>: type structures representing type <code>T</code>.</li>
</ul>
<p>Quoting takes expressions of type <code>T</code> to expressions of type <code>Expr[T]</code>
and it takes types <code>T</code> to expressions of type <code>Type[T]</code>. Splicing
takes expressions of type <code>Expr[T]</code> to expressions of type <code>T</code> and it
takes expressions of type <code>Type[T]</code> to types <code>T</code>.</p>
<p>The two types can be are defined in package <code>scala.quoted</code> as follows:</p>
<pre><code>package scala.quoted

abstract class Expr[T] {
  def unary_~: T   // splice operation
}
class Type[T] {
  type unary_~ = T  // splice type
}
</code></pre>
<h3><a href="#the-phase-consistency-principle" id="the-phase-consistency-principle">The Phase Consistency Principle</a></h3>
<p>A fundamental <em>phase consistency principle</em> (PCP) regulates accesses
to free variables in quoted and spliced code:</p>
<ul>
<li><em>For any free variable reference <code>x</code>, the number of quoted scopes and the number of spliced scopes between the reference to <code>x</code> and the definition of <code>x</code> must be equal</em>.</li>
</ul>
<p>Here, <code>this</code>-references count as free variables. On the other
hand, we assume that all imports are fully expanded and that <code>_root_</code> is
not a free variable. So references to global definitions are
allowed everywhere.</p>
<p>The phase consistency principle can be motivated as follows: First,
suppose the result of a program <code>P</code> is some quoted text <code>’{ ... x ... }</code> that refers to a free variable <code>x</code> in <code>P</code> This can be
represented only by referring to the original variable <code>x</code>. Hence, the
result of the program will need to persist the program state itself as
one of its parts. We don’t want to do this, hence this situation
should be made illegal. Dually, suppose a top-level part of a program
is a spliced text <code>~{ ... x ... }</code> that refers to a free variable <code>x</code>
in <code>P</code>.  This would mean that we refer during <em>construction</em> of <code>P</code> to
a value that is available only during <em>execution</em> of <code>P</code>. This is of
course impossible and therefore needs to be ruled out.  Now, the
small-step evaluation of a program will reduce quotes and splices in
equal measure using the cancellation rules above. But it will neither
create nor remove quotes or splices individually. So the PCP ensures
that program elaboration will lead to neither of the two unwanted
situations described above.</p>
<p>In what concerns the range of features it covers, symmetric meta programming is
quite close to the MetaML family of languages. One difference is that MetaML does
not have an equivalent of the PCP - quoted code in MetaML <em>can</em> access
variables in its immediately enclosing environment, with some
restrictions and caveats since such accesses involve serialization.
However, this does not constitute a fundamental gain in
expressiveness. Symmetric meta programming allows to define a <code>Liftable</code>
type-class which can implement such accesses within the confines of the
PCP. This is explained further in a later section.</p>
<h2><a href="#details" id="details">Details</a></h2>
<h3><a href="#from-s-to-functions-and-back" id="from-s-to-functions-and-back">From <code>Expr</code>s to Functions and Back</a></h3>
<p>The <code>Expr</code> companion object contains an &quot;AsFunction&quot; decorator that turns a tree
describing a function into a function mapping trees to trees.</p>
<pre><code>object Expr {
  ...
  implicit class AsFunction[T, U](f: Expr[T =&gt; U]) extends AnyVal {
    def apply(x: Expr[T]): Expr[U] = ???
  }
}
</code></pre>
<p>This decorator gives <code>Expr</code> the <code>apply</code> operation of an applicative functor, where <code>Expr</code>s
over function types can be applied to <code>Expr</code> arguments. The definition
of <code>AsFunction(f).apply(x)</code> is assumed to be functionally the same as
<code>’((~f)(~x))</code>, however it should optimize this call by returning the
result of beta-reducing <code>f(x)</code> if <code>f</code> is a known lambda expression</p>
<p>The <code>AsFunction</code> decorator distributes applications of <code>Expr</code> over function
arrows:</p>
<pre><code>AsFunction(_).apply: Expr[S =&gt; T] =&gt; (Expr[S] =&gt; Expr[T])
</code></pre>
<p>Its dual, let’s call it <code>reflect</code>, can be defined as follows:</p>
<pre><code>def reflect[T, U](f: Expr[T] =&gt; Expr[U]): Expr[T =&gt; U] = ’{
  (x: T) =&gt; ~f(’(x))
}
</code></pre>
<p>Note how the fundamental phase consistency principle works in two
different directions here for <code>f</code> and <code>x</code>.  The reference to <code>f</code> is
legal because it is quoted, then spliced, whereas the reference to <code>x</code>
is legal because it is spliced, then quoted.</p>
<h3><a href="#types-and-the-pcp" id="types-and-the-pcp">Types and the PCP</a></h3>
<p>In principle, The phase consistency principle applies to types as well
as for expressions. This might seem too restrictive. Indeed, the
definition of <code>reflect</code> above is not phase correct since there is a
quote but no splice between the parameter binding of <code>T</code> and its
usage. But the code can be made phase correct by adding a binding
of a <code>Type[T]</code> tag:</p>
<pre><code>def reflect[T, U](f: Expr[T] =&gt; Expr[U]): Expr[T =&gt; U] = {
  val Ttag = new Type[T]
  ’{ (x: ~Ttag) =&gt; ~f(’(x))
}
</code></pre>
<p>To avoid clutter, the Scala implementation will add these tags
automatically in the case of a PCP violation involving types. As a consequence,
types can be effectively ignored for phase consistency checking.</p>
<h3><a href="#example-expansion" id="example-expansion">Example Expansion</a></h3>
<p>Assume an <code>Array</code> class with an inline <code>map</code> method that forwards to a macro implementation.</p>
<pre><code>class Array[T] {
  inline def map[U](f: T =&gt; U): Array[U] = ~ Macros.mapImpl[T, U](’[U], ’(this), ’(f))
}
</code></pre>
<p>Here’s the definition of the <code>mapImpl</code> macro, which takes quoted types and expressions to a quoted expression:</p>
<pre><code>object Macros {

  def mapImpl[T, U](u: Type[U], arr: Expr[Array[T]], op: Expr[T =&gt; U]): Expr[Array[U]] = ’{
    var i = 0
    val xs = ~arr
    var len = xs.length
    val ys = new Array[~u]
    while (i &lt; len) {
      ys(i) = ~op(’(xs(i)))
      i += 1
    }
    ys
  }
}
</code></pre>
<p>Here’s an application of <code>map</code> and how it rewrites to optimized code:</p>
<pre><code>genSeq[Int]().map(x =&gt; x + 1)
</code></pre>
<p>==&gt; (inline)</p>
<pre><code>val $this: Seq[Int] = genSeq[Int]()
val f: Int =&gt; Int = x =&gt; x * x
~ _root_.Macros.mapImpl[Int, Int](’[Int], ’($this), ’(f))
</code></pre>
<p>==&gt; (splice)</p>
<pre><code>val $this: Seq[Int] = genSeq[Int]()
val f: Int =&gt; Int = x =&gt; x * x

{
  var i = 0
  val xs = ~’($this)
  var len = xs.length
  val ys = new Array[~’[Int]]
  while (i &lt; len) {
    ys(i) = ~(’(f)(’(xs(i))))
    i += 1
  }
  ys
}
</code></pre>
<p>==&gt; (expand and splice inside quotes)</p>
<pre><code>val $this: Seq[Int] = genSeq[Int]()
val f: Int =&gt; Int = x =&gt; x * x

{
  var i = 0
  val xs = $this
  var len = xs.length
  val ys = new Array[Int]
  while (i &lt; len) {
    ys(i) = xs(i) + 1
    i += 1
  }
  ys
}
</code></pre>
<p>==&gt; (elim dead code)</p>
<pre><code>val $this: Seq[Int] = genSeq[Int]()

{
  var i = 0
  val xs = $this
  var len = xs.length
  val ys = new Array[Int]
  while (i &lt; len) {
    ys(i) = xs(i) + 1
    i += 1
  }
  ys
}
</code></pre>
<h3><a href="#relationship-with-inline-and-macros" id="relationship-with-inline-and-macros">Relationship with Inline and Macros</a></h3>
<p>Seen by itself, symmetric meta-programming looks more like a
framework for staging than one for compile-time meta programming with
macros. But combined with Dotty’s <code>inline</code> it can be turned into a
compile-time system.  The idea is that macro elaboration can be
understood as a combination of a macro library and a quoted
program. For instance, here’s the <code>assert</code> macro again together with a
program that calls <code>assert</code>.</p>
<pre><code>object Macros {

  inline def assert(expr: =&gt; Boolean): Unit =
    ~ assertImpl(’(expr))

  def assertImpl(expr: Expr[Boolean]) =
    ’{ if !(~expr) then throw new AssertionError(s&quot;failed assertion: ${~expr}&quot;) }
}

val program = {
  val x = 1
  Macros.assert(x != 0)
}
</code></pre>
<p>Inlining the <code>assert</code> function would give the following program:</p>
<pre><code>val program = {
  val x = 1
  ~Macros.assertImpl(’(x != 0))
}
</code></pre>
<p>The example is only phase correct because Macros is a global value and
as such not subject to phase consistency checking. Conceptually that’s
a bit unsatisfactory. If the PCP is so fundamental, it should be
applicable without the global value exception. But in the example as
given this does not hold since both <code>assert</code> and <code>program</code> call
<code>assertImpl</code> with a splice but no quote.</p>
<p>However, one can could argue that the example is really missing
an important aspect: The macro library has to be compiled in a phase
prior to the program using it, but in the code above, macro
and program are defined together. A more accurate view of
macros would be to have the user program be in a phase after the macro
definitions, reflecting the fact that macros have to be defined and
compiled before they are used. Hence, conceptually the program part
should be treated by the compiler as if it was quoted:</p>
<pre><code>val program = ’{
  val x = 1
  ~Macros.assertImpl(’(x != 0))
}
</code></pre>
<p>If <code>program</code> is treated as a quoted expression, the call to
<code>Macro.assertImpl</code> becomes phase correct even if macro library and
program are conceptualized as local definitions.</p>
<p>But what about the call from <code>assert</code> to <code>assertImpl</code>? Here, we need a
tweak of the typing rules. An inline function such as <code>assert</code> that
contains a splice operation outside an enclosing quote is called a
<em>macro</em>. Macros are supposed to be expanded in a subsequent phase,
i.e. in a quoted context. Therefore, they are also type checked as if
they were in a quoted context. For instance, the definition of
<code>assert</code> is typechecked as if it appeared inside quotes.  This makes
the call from <code>assert</code> to <code>assertImpl</code> phase-correct, even if we
assume that both definitions are local.</p>
<p>The second role of <code>inline</code> in Dotty is to mark a <code>val</code> that is
either a constant or is a parameter that will be a constant when instantiated. This
aspect is also important for macro expansion.  To illustrate this,
consider an implementation of the <code>power</code> function that makes use of a
statically known exponent:</p>
<pre><code>inline def power(inline n: Int, x: Double) = ~powerCode(n, ’(x))

private def powerCode(n: Int, x: Expr[Double]): Expr[Double] =
  if (n == 0) ’(1.0)
  else if (n == 1) x
  else if (n % 2 == 0) ’{ { val y = ~x * ~x; ~powerCode(n / 2, ’(y)) } }
  else ’{ ~x * ~powerCode(n - 1, x) }
</code></pre>
<p>The reference to <code>n</code> as an argument in <code>~powerCode(n, ’(x))</code> is not
phase-consistent, since <code>n</code> appears in a splice without an enclosing
quote. Normally that would be a problem because it means that we need
the <em>value</em> of <code>n</code> at compile time, which is not available for general
parameters. But since <code>n</code> is an inline parameter of a macro, we know
that at the macro’s expansion point <code>n</code> will be instantiated to a
constant, so the value of <code>n</code> will in fact be known at this
point. To reflect this, we loosen the phase consistency requirements
as follows:</p>
<ul>
<li>If <code>x</code> is an inline value (or an inline parameter of an inline
function), it can be accessed in all contexts where the number of
splices minus the number of quotes between use and definition is
either 0 or 1.</li>
</ul>
<h3><a href="#relationship-with-staging" id="relationship-with-staging">Relationship with Staging</a></h3>
<p>The framework expresses at the same time compile-time meta-programming
and staging. The phase in which code is run is determined by the
difference between the number of splice scopes and quote scopes in
which it is embedded.</p>
<ul>
<li>
<p>If there are more splices than quotes, the code is run at
&quot;compile-time&quot; i.e. as a macro. In the general case, this means
running an interpreter that evaluates the code, which is
represented as a typed abstract syntax tree. The interpreter can
fall back to reflective calls when evaluating an application of a
previously compiled method.  If the splice excess is more than one,
it would mean that a macro’s implementation code (as opposed to the
code it expands to) invokes other macros. If macros are realized by
interpretation, this would lead to towers of interpreters, where
the first interpreter would itself interpret an interpreter code
that possibly interprets another interpreter and so on.</p>
</li>
<li>
<p>If the number of splices equals the number of quotes, the code is
compiled and run as usual.</p>
</li>
<li>If the number of quotes exceeds the number of splices, the code is
staged. That is, it produces a typed abstract syntax tree or type
structure at run-time. A quote excess of more than one corresponds
to multi-staged programming.</li>
</ul>
<p>Providing an interpreter for the full language is quite difficult, and
it is even more difficult to make that interpreter run efficiently. So
we currently impose the following restrictions on the use of splices.</p>
<ol>
<li>
<p>A top-level splice must appear in an inline function (turning that function
into a macro)</p>
</li>
<li>
<p>The splice must call a previously compiled method.</p>
</li>
<li>
<p>Splices inside splices (but no intervening quotes) are not allowed.</p>
</li>
<li>A macro method is effectively final and it may override no other method.</li>
</ol>
<p>The framework as discussed so far allows code to be staged, i.e. be prepared
to be executed at a later stage. To run that code, there is another method
in class <code>Expr</code> called <code>run</code>. Note that <code>~</code> and <code>run</code> both map from <code>Expr[T]</code>
to <code>T</code> but only <code>~</code> is subject to the PCP, whereas <code>run</code> is just a normal method.</p>
<pre><code>abstract class Expr[T] {
  def unary_~: T
  def run: T     // run staged code
}
</code></pre>
<h3><a href="#limitations-to-splicing" id="limitations-to-splicing">Limitations to Splicing</a></h3>
<p>Quotes and splices are duals as far as the PCP is concerned. But there is an additional
restriction that needs to be imposed on splices to guarantee soundness:
code in splices must be free of side effects. The restriction prevents code like this:</p>
<pre><code> var x: Expr[T]
 ’{ (y: T) =&gt; ~{ x = ’(y); 1 } }
</code></pre>
<p>This code, if it was accepted, would &quot;extrude&quot; a reference to a quoted variable <code>y</code> from its scope.
This means we an subsequently access a variable outside the scope where it is defined, which is
likely problematic. The code is clearly phase consistent, so we cannot use PCP to
rule it out. Instead we postulate a future effect system that can guarantee that splices
are pure. In the absence of such a system we simply demand that spliced expressions are
pure by convention, and allow for undefined compiler behavior if they are not. This is analogous
to the status of pattern guards in Scala, which are also required, but not verified, to be pure.</p>
<p>There is also a problem with <code>run</code> in splices. Consider the following expression:</p>
<pre><code>’{ (x: Int) =&gt; ~{ {’(x)}.run; 1 } }
</code></pre>
<p>This is again phase correct, but will lead us into trouble. Indeed, evaluating the splice will reduce the
expression <code>{’(x)}.run</code> to <code>x</code>. But then the result</p>
<pre><code>’{ (x: Int) =&gt; ~{ x; 1 } }
</code></pre>
<p>is no longer phase correct. To prevent this soundness hole it seems easiest to classify <code>run</code> as a side-effecting
operation. It would thus be prevented from appearing in splices. In a base language with side-effects we'd have to
do this anyway: Since <code>run</code> runs arbitrary code it can always produce a side effect if the code it runs produces one.</p>
<h3><a href="#the--type-class" id="the--type-class">The <code>Liftable</code> type-class</a></h3>
<p>Consider the following implementation of a staged interpreter that implements
a compiler through staging.</p>
<pre><code>import scala.quoted._

enum Exp {
  case Num(n: Int)
  case Plus(e1: Exp, e2: Exp)
  case Var(x: String)
  case Let(x: String, e: Exp, in: Exp)
}
</code></pre>
<p>The interpreted language consists of numbers <code>Num</code>, addition <code>Plus</code>, and variables
<code>Var</code> which are bound by <code>Let</code>. Here are two sample expressions in the language:</p>
<pre><code>val exp = Plus(Plus(Num(2), Var(&quot;x&quot;)), Num(4))
val letExp = Let(&quot;x&quot;, Num(3), exp)
</code></pre>
<p>Here’s a compiler that maps an expression given in the interpreted
language to quoted Scala code of type <code>Expr[Int]</code>.
The compiler takes an environment that maps variable names to Scala <code>Expr</code>s.</p>
<pre><code>def compile(e: Exp, env: Map[String, Expr[Int]]): Expr[Int] = e match {
  case Num(n) =&gt;
    n
  case Plus(e1, e2) =&gt;
    ’(~compile(e1, env) + ~compile(e2, env))
  case Var(x) =&gt;
    env(x)
  case Let(x, e, body) =&gt;
    ’{ val y = ~compile(e, env); ~compile(body, env + (x -&gt; ’(y))) }
}
</code></pre>
<p>Running <code>compile(letExp, Map())</code> would yield the following Scala code:</p>
<pre><code>’{ val y = 3; (2 + y) + 4 }
</code></pre>
<p>The body of the first clause, <code>case Num(n) =&gt; n</code>, looks suspicious. <code>n</code>
is declared as an <code>Int</code>, yet the result of <code>compile</code> is declared to be
<code>Expr[Int]</code>. Shouldn’t <code>n</code> be quoted? In fact this would not
work since replacing <code>n</code> by <code>’n</code> in the clause would not be phase
correct.</p>
<p>What happens instead &quot;under the hood&quot; is an implicit conversion: <code>n</code>
is expanded to <code>scala.quoted.Expr.toExpr(n)</code>. The <code>toExpr</code> conversion
is defined in the companion object of class <code>Expr</code> as follows:</p>
<pre><code>object Expr {
  implicit def toExpr[T](x: T)(implicit ev: Liftable[T]): Expr[T] =
    ev.toExpr(x)
}
</code></pre>
<p>The conversion says that values of types implementing the <code>Liftable</code>
type class can be converted (&quot;lifted&quot;) automatically to <code>Expr</code>
values. Dotty comes with instance definitions of <code>Liftable</code> for
several types including all underlying types of literals. For example,
<code>Int</code> values can be converted to <code>Expr[Int]</code> values by wrapping the
value in a <code>Literal</code> tree node. This makes use of the underlying tree
representation in the compiler for efficiency. But the <code>Liftable</code>
instances are nevertheless not &quot;magic&quot; in the sense that they could
all be defined in a user program without knowing anything about the
representation of <code>Expr</code> trees. For instance, here is a possible
instance of <code>Liftable[Boolean]</code>:</p>
<pre><code>implicit def BooleanIsLiftable: Liftable[Boolean] = new {
  implicit def toExpr(b: Boolean) = if (b) ’(true) else ’(false)
}
</code></pre>
<p>Once we can lift bits, we can work our way up. For instance, here is a
possible implementation of <code>Liftable[Int]</code> that does not use the underlying
tree machinery:</p>
<pre><code>implicit def IntIsLiftable: Liftable[Int] = new {
  def toExpr(n: Int): Expr[Int] = n match {
    case Int.MinValue    =&gt; ’(Int.MinValue)
    case _ if n &lt; 0      =&gt; ’(-(~toExpr(n)))
    case 0               =&gt; ’(0)
    case _ if n % 2 == 0 =&gt; ’(~toExpr(n / 2) * 2)
    case _               =&gt; ’(~toExpr(n / 2) * 2 + 1)
  }
}
</code></pre>
<p>Since <code>Liftable</code> is a type class, its instances can be conditional. For example,
a <code>List</code> is liftable if its element type is:</p>
<pre><code>implicit def ListIsLiftable[T: Liftable]: Liftable[List[T]] = new {
  def toExpr(xs: List[T]): Expr[List[T]] = xs match {
    case x :: xs1 =&gt; ’(~implicitly[Liftable[T]].toExpr(x) :: ~toExpr(xs1))
    case Nil =&gt; ’(Nil: List[T])
  }
}
</code></pre>
<p>In the end, <code>Liftable</code> resembles very much a serialization
framework. Like the latter it can be derived systematically for all
collections, case classes and enums.</p>
<h2><a href="#implementation" id="implementation">Implementation</a></h2>
<h3><a href="#syntax-changes" id="syntax-changes">Syntax changes</a></h3>
<p>A splice <code>~e</code> on an expression of type <code>Expr[T]</code> is a normal prefix
operator. To make it work as a type operator on <code>Type[T]</code> as well, we
need a syntax change that introduces prefix operators as types.</p>
<pre><code>  SimpleType        ::=  ...
                         [‘-’ | ‘+’ | ‘~’ | ‘!’] StableId
</code></pre>
<p>Analogously to the situation with expressions, a prefix type operator
such as <code>~ e</code> is treated as a shorthand for the type <code>e.unary_~</code>.</p>
<p>Quotes are supported by introducing new tokens <code>’(</code>, <code>’{</code>, and <code>’[</code>
and adding quoted variants <code>’(...)</code>, <code>’{...}</code> and <code>’[...]</code> to the
<code>SimpleExpr</code> productions.</p>
<pre><code>  SimpleExpr        ::=  ...
                      |  ‘’{’ BlockExprContents ‘}’
                      |  ‘’’ ‘(’ ExprsInParens ‘)’
                      |  ‘’’ ‘[’ Type ‘]’
</code></pre>
<p>Syntax changes are given relative to the <a href="../internal/syntax.html">Dotty reference
grammar</a>.</p>
<p>An alternative syntax would treat <code>’</code> as a separate operator. This
would be attractive since it enables quoting single identifiers as
e.g. <code>’x</code> instead of <code>’(x)</code>. But it would clash with symbol
literals. So it could be done only if symbol literals were abolished.</p>
<h3><a href="#implementation-in-" id="implementation-in-">Implementation in <code>dotc</code></a></h3>
<p>Quotes and splices are primitive forms in the generated abstract
syntax trees. They are eliminated in an expansion phase
<code>ReifyQuotes</code>. This phase runs after typing and pickling.</p>
<p>Macro-expansion works outside-in. If the outermost scope is a splice,
the spliced AST will be evaluated in an interpreter. A call to a
previously compiled method can be implemented as a reflective call to
that method. With the restrictions on splices that are currently in
place that’s all that’s needed. We might allow more interpretation in
splices in the future, which would allow us to loosen the
restriction.  Quotes in spliced, interpreted code are kept as they
are, after splices nested in the quotes are expanded.</p>
<p>If the outermost scope is a quote, we need to generate code that
constructs the quoted tree at run-time. We implement this by
serializing the tree as a Tasty structure, which is stored
in a string literal. At runtime, an unpickler method is called to
deserialize the string into a tree.</p>
<p>Splices inside quoted code insert the spliced tree as is, after
expanding any quotes in the spliced code recursively.</p>
<h2><a href="#formalization" id="formalization">Formalization</a></h2>
<p>The phase consistency principle can be formalized in a calculus that
extends simply-typed lambda calculus with quotes and splices.</p>
<h3><a href="#syntax" id="syntax">Syntax</a></h3>
<p>The syntax of terms, values, and types is given as follows:</p>
<pre><code>Terms         t  ::=  x                 variable
                      (x: T) =&gt; t       lambda
                      t t               application
                      ’t                quote
                      ~t                splice

Values        v  ::=  (x: T) =&gt; t       lambda
                      ’q                pure quote

Quoted        q  ::=  x  |  (x: T) =&gt; q  |  q q  |  ’t

Types         T  ::=  A                 base type
                      T -&gt; T            function type
                      expr T            quoted
</code></pre>
<p>Typing rules are formulated using a stack of environments
<code>Es</code>. Individual environments <code>E</code> consist as usual of variable
bindings <code>x: T</code>. Environments can be combined using the two
combinators <code>’</code> and <code>~</code>.</p>
<pre><code>Environment   E  ::=  ()                empty
                      E, x: T

Env. stack    Es ::=  ()                empty
                      E                 simple
                      Es * Es           combined

Separator     *  ::=  ’
                      ~
</code></pre>
<p>The two environment combinators are both associative with left and
right identity <code>()</code>.</p>
<h3><a href="#operational-semantics" id="operational-semantics">Operational semantics:</a></h3>
<p>We define a small step reduction relation <code>--&gt;</code> with the following rules:</p>
<pre><code>            ((x: T) =&gt; t) v  --&gt;  [x := v]t

                      ~(’t)  --&gt;  t

                         t1  --&gt;  t2
                      -----------------
                      e[t1]  --&gt;  e[t2]
</code></pre>
<p>The first rule is standard call-by-value beta-reduction. The second
rule says that splice and quotes cancel each other out. The third rule
is a context rule; it says that reduction is allowed in the hole <code>[ ]</code>
position of an evaluation context.  Evaluation contexts <code>e</code> and
splice evaluation context <code>e_s</code> are defined syntactically as follows:</p>
<pre><code>Eval context    e    ::=  [ ]  |  e t  |  v e  |  ’e_s[~e]
Splice context  e_s  ::=  [ ]  |  (x: T) =&gt; e_s  |  e_s t  |  q e_s
</code></pre>
<h3><a href="#typing-rules" id="typing-rules">Typing rules</a></h3>
<p>Typing judgments are of the form <code>Es |- t: T</code>. There are two
substructural rules which express the fact that quotes and splices
cancel each other out:</p>
<pre><code>                      Es1 * Es2 |- t: T
                 ---------------------------
                 Es1 ~ E1 ’ E2 * Es2 |- t: T


                      Es1 * Es2 |- t: T
                 ---------------------------
                 Es1 ’ E1 ~ E2 * Es2 |- t: T
</code></pre>
<p>The lambda calculus fragment of the rules is standard, except that we
use a stack of environments. The rules only interact with the topmost
environment of the stack.</p>
<pre><code>                          x: T in E
                        --------------
                        Es * E |- x: T


                    Es * E, x: T1 |- t: T2
                -------------------------------
                Es * E |- (x: T1) =&gt; t: T -&gt; T2


               Es |- t1: T2 -&gt; T    Es |- t2: T2
               ---------------------------------
                      Es |- t1 t2: T
</code></pre>
<p>The rules for quotes and splices map between <code>expr T</code> and <code>T</code> by trading <code>’</code> and <code>~</code> between
environments and terms.</p>
<pre><code>                     Es ~ () |- t: expr T
                     --------------------
                         Es |- ~t: T


                       Es ’ () |- t: T
                       ----------------
                       Es |- ’t: expr T
</code></pre>
<h2><a href="#going-further" id="going-further">Going Further</a></h2>
<p>The meta-programming framework as presented and currently implemented is quite restrictive
in that it does not allow for the inspection of quoted expressions and
types. It’s possible to work around this by providing all necessary
information as normal, unquoted inline parameters. But we would gain
more flexibility by allowing for the inspection of quoted code with
pattern matching. This opens new possibilities. For instance, here is a
version of <code>power</code> that generates the multiplications directly if the
exponent is statically known and falls back to the dynamic
implementation of power otherwise.</p>
<pre><code>inline def power(n: Int, x: Double): Double = ~{
  ’(n) match {
    case Constant(n1) =&gt; powerCode(n1, ’(x))
    case _ =&gt; ’{ dynamicPower(n, x) }
  }
}

private def dynamicPower(n: Int, x: Double): Double =
  if (n == 0) 1.0
  else if (n % 2 == 0) dynamicPower(n / 2, x * x)
  else x * dynamicPower(n - 1, x)
</code></pre>
<p>This assumes a <code>Constant</code> extractor that maps tree nodes representing
constants to their values.</p>
<p>With the right extractors the &quot;AsFunction&quot; operation
that maps expressions over functions to functions over expressions can
be implemented in user code:</p>
<pre><code>implicit class AsFunction[T, U](f: Expr[T =&gt; U]) extends AnyVal {
  def apply(x: Expr[T]): Expr[U] =
    f match {
      case Lambda(g) =&gt; g(x)
      case _ =&gt; ’((~f)(~x))
    }
</code></pre>
<p>This assumes an extractor</p>
<pre><code>object Lambda {
  def unapply[T, U](x: Expr[T =&gt; U]): Option[Expr[T] =&gt; Expr[U]]
}
</code></pre>
<p>Once we allow inspection of code via extractors, it’s tempting to also
add constructors that create typed trees directly without going
through quotes. Most likely, those constructors would work over <code>Expr</code>
types which lack a known type argument. For instance, an <code>Apply</code>
constructor could be typed as follows:</p>
<pre><code>def Apply(fn: Expr[_], args: List[Expr[_]]): Expr[_]
</code></pre>
<p>This would allow constructing applications from lists of arguments
without having to match the arguments one-by-one with the
corresponding formal parameter types of the function. We then need &quot;at
the end&quot; a method to convert an <code>Expr[_]</code> to an <code>Expr[T]</code> where <code>T</code> is
given from the outside. E.g. if <code>code</code> yields a <code>Expr[_]</code>, then
<code>code.atType[T]</code> yields an <code>Expr[T]</code>. The <code>atType</code> method has to be
implemented as a primitive; it would check that the computed type
structure of <code>Expr</code> is a subtype of the type structure representing
<code>T</code>.</p>
<p>Before going down that route, we should evaluate in detail the tradeoffs it
presents.  Constructing trees that are only verified <em>a posteriori</em>
to be type correct loses a lot of guidance for constructing the right
trees.  So we should wait with this addition until we have more
use-cases that help us decide whether the loss in type-safety is worth
the gain in flexibility. In this context, it seems that deconstructing types is
less error-prone than deconstructing terms, so one might also
envisage a solution that allows the former but not the latter.</p>
<h2><a href="#conclusion" id="conclusion">Conclusion</a></h2>
<p>Meta-programming has a reputation of being difficult and confusing.
But with explicit <code>Expr/Type</code> types and quotes and splices it can become
downright pleasant. A simple strategy first defines the underlying quoted or unquoted
values using <code>Expr</code> and <code>Type</code> and then inserts quotes and splices to make the types
line up. Phase consistency is at the same time a great guideline
where to insert a splice or a quote and a vital sanity check that
the result makes sense.</p>
